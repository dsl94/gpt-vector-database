{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-Powered Chatbots: Enriching Conversations with Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\nThe current President of the United States is Joe Biden.'"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"\"\n",
    "\n",
    "prompt = \"Who is the president of USA\"\n",
    "\n",
    "response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0, max_tokens=1000)\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens if we ask it something that it does not know, or it think it knows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What benefits badin soft provides to it's employees?\"\n",
    "response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0, max_tokens=1000)\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding too much text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 5125 tokens (4125 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidRequestError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[82], line 95\u001B[0m\n\u001B[1;32m      1\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mUse the below article to answer questions about Badin in serbian, if you don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt know the answer write \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNa Å¾alost ne znam odgovor, molim te da se obratis HR ili OFA sluÅ¾bi.:\u001B[39m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124m     Article:\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;124m    Question: Koja su badin gesla?\u001B[39m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m---> 95\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext-davinci-003\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m response[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/openai/lib/python3.8/site-packages/openai/api_resources/completion.py:25\u001B[0m, in \u001B[0;36mCompletion.create\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 25\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m TryAgain \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m>\u001B[39m start \u001B[38;5;241m+\u001B[39m timeout:\n",
      "File \u001B[0;32m~/anaconda3/envs/openai/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    137\u001B[0m ):\n\u001B[1;32m    138\u001B[0m     (\n\u001B[1;32m    139\u001B[0m         deployment_id,\n\u001B[1;32m    140\u001B[0m         engine,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    150\u001B[0m         api_key, api_base, api_type, api_version, organization, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[1;32m    151\u001B[0m     )\n\u001B[0;32m--> 153\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[1;32m    164\u001B[0m         \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n\u001B[1;32m    165\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, OpenAIResponse)\n",
      "File \u001B[0;32m~/anaconda3/envs/openai/lib/python3.8/site-packages/openai/api_requestor.py:226\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    207\u001B[0m     method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    214\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    215\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m    216\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_raw(\n\u001B[1;32m    217\u001B[0m         method\u001B[38;5;241m.\u001B[39mlower(),\n\u001B[1;32m    218\u001B[0m         url,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    224\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[1;32m    225\u001B[0m     )\n\u001B[0;32m--> 226\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[0;32m~/anaconda3/envs/openai/lib/python3.8/site-packages/openai/api_requestor.py:620\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[0;34m(self, result, stream)\u001B[0m\n\u001B[1;32m    612\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m    613\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response_line(\n\u001B[1;32m    614\u001B[0m             line, result\u001B[38;5;241m.\u001B[39mstatus_code, result\u001B[38;5;241m.\u001B[39mheaders, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    615\u001B[0m         )\n\u001B[1;32m    616\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m parse_stream(result\u001B[38;5;241m.\u001B[39miter_lines())\n\u001B[1;32m    617\u001B[0m     ), \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    619\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m--> 620\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response_line\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    621\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    624\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    625\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    626\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    627\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/openai/lib/python3.8/site-packages/openai/api_requestor.py:683\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[0;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[1;32m    681\u001B[0m stream_error \u001B[38;5;241m=\u001B[39m stream \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m    682\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream_error \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rcode \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m:\n\u001B[0;32m--> 683\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_error_response(\n\u001B[1;32m    684\u001B[0m         rbody, rcode, resp\u001B[38;5;241m.\u001B[39mdata, rheaders, stream_error\u001B[38;5;241m=\u001B[39mstream_error\n\u001B[1;32m    685\u001B[0m     )\n\u001B[1;32m    686\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[0;31mInvalidRequestError\u001B[0m: This model's maximum context length is 4097 tokens, however you requested 5125 tokens (4125 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Use the below article to answer questions about benefits in our company, if you don't know the answer write \"Sorry I don't know the answer please contact HR:\n",
    "     Article:\n",
    "    \\\"\\\"\\\"\n",
    "    At SuperAwsomeCompany, we prioritize the well-being and professional growth of our employees. That's why we are proud to offer a comprehensive range of benefits designed to support our team members in various aspects of their lives.\n",
    "\n",
    "Our benefits package includes top-tier health insurance options, ensuring that you and your family have access to quality healthcare and financial security. Additionally, we provide robust retirement plans, such as our competitive 401(k) program, which allows you to save for a secure future while enjoying the added advantage of employer matching contributions.\n",
    "\n",
    "Work-life balance is essential to us, which is why we offer generous paid time off that encompasses vacation days, sick leave, personal days, and holidays. This way, you can take the time you need to rest, rejuvenate, and spend quality time with your loved ones.\n",
    "\n",
    "Recognizing the changing nature of work, we also embrace flexible work arrangements. Whether it's telecommuting or flexible scheduling, we understand the importance of accommodating your needs and empowering you to achieve a better work-life integration.\n",
    "\n",
    "We are committed to the holistic well-being of our employees, which is why we provide access to employee assistance programs (EAPs). These programs offer confidential counseling services, mental health support, financial advice, and resources for childcare or eldercare, ensuring that you have the support you need during challenging times.\n",
    "\n",
    "Investing in your professional growth is another priority for us. That's why we offer a range of opportunities for career development and training. From in-house workshops and seminars to external conferences and tuition reimbursement for further education, we're dedicated to helping you enhance your skills, succeed in your role, and progress in your career.\n",
    "\n",
    "At SuperAwsomeCompany, we believe that our employees are our greatest asset. That's why we go above and beyond to provide a comprehensive benefits package that fosters your well-being, personal growth, and work satisfaction.\n",
    "At SuperAwsomeCompany, we prioritize the well-being and professional growth of our employees. That's why we are proud to offer a comprehensive range of benefits designed to support our team members in various aspects of their lives.\n",
    "\n",
    "Our benefits package includes top-tier health insurance options, ensuring that you and your family have access to quality healthcare and financial security. Additionally, we provide robust retirement plans, such as our competitive 401(k) program, which allows you to save for a secure future while enjoying the added advantage of employer matching contributions.\n",
    "\n",
    "Work-life balance is essential to us, which is why we offer generous paid time off that encompasses vacation days, sick leave, personal days, and holidays. This way, you can take the time you need to rest, rejuvenate, and spend quality time with your loved ones.\n",
    "\n",
    "Recognizing the changing nature of work, we also embrace flexible work arrangements. Whether it's telecommuting or flexible scheduling, we understand the importance of accommodating your needs and empowering you to achieve a better work-life integration.\n",
    "\n",
    "We are committed to the holistic well-being of our employees, which is why we provide access to employee assistance programs (EAPs). These programs offer confidential counseling services, mental health support, financial advice, and resources for childcare or eldercare, ensuring that you have the support you need during challenging times.\n",
    "\n",
    "Investing in your professional growth is another priority for us. That's why we offer a range of opportunities for career development and training. From in-house workshops and seminars to external conferences and tuition reimbursement for further education, we're dedicated to helping you enhance your skills, succeed in your role, and progress in your career.\n",
    "\n",
    "At SuperAwsomeCompany, we believe that our employees are our greatest asset. That's why we go above and beyond to provide a comprehensive benefits package that fosters your well-being, personal growth, and work satisfaction.\n",
    "At SuperAwsomeCompany, we prioritize the well-being and professional growth of our employees. That's why we are proud to offer a comprehensive range of benefits designed to support our team members in various aspects of their lives.\n",
    "\n",
    "Our benefits package includes top-tier health insurance options, ensuring that you and your family have access to quality healthcare and financial security. Additionally, we provide robust retirement plans, such as our competitive 401(k) program, which allows you to save for a secure future while enjoying the added advantage of employer matching contributions.\n",
    "\n",
    "Work-life balance is essential to us, which is why we offer generous paid time off that encompasses vacation days, sick leave, personal days, and holidays. This way, you can take the time you need to rest, rejuvenate, and spend quality time with your loved ones.\n",
    "\n",
    "Recognizing the changing nature of work, we also embrace flexible work arrangements. Whether it's telecommuting or flexible scheduling, we understand the importance of accommodating your needs and empowering you to achieve a better work-life integration.\n",
    "\n",
    "We are committed to the holistic well-being of our employees, which is why we provide access to employee assistance programs (EAPs). These programs offer confidential counseling services, mental health support, financial advice, and resources for childcare or eldercare, ensuring that you have the support you need during challenging times.\n",
    "\n",
    "Investing in your professional growth is another priority for us. That's why we offer a range of opportunities for career development and training. From in-house workshops and seminars to external conferences and tuition reimbursement for further education, we're dedicated to helping you enhance your skills, succeed in your role, and progress in your career.\n",
    "\n",
    "At SuperAwsomeCompany, we believe that our employees are our greatest asset. That's why we go above and beyond to provide a comprehensive benefits package that fosters your well-being, personal growth, and work satisfaction.\n",
    "    \\\"\\\"\\\"\n",
    "    Question: Give me best benefit?\n",
    "\"\"\"\n",
    "response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0, max_tokens=1000)\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating vector from text using GPT vector embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Simple text\"\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "openai.Embedding.create(input = [text], model=\"text-embedding-ada-002\")['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milvius connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymilvus import (\n",
    "    connections,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    ")\n",
    "\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milvius schema creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
    "    FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=300),\n",
    "    FieldSchema(name=\"file_name\", dtype=DataType.VARCHAR, max_length=300),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=1536)\n",
    "]\n",
    "schema = CollectionSchema(fields, \"articles with titles\")\n",
    "article_collection = Collection(\"articles2\", schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milvius indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_params = {\n",
    "    \"metric_type\":\"L2\",\n",
    "    \"index_type\":\"IVF_FLAT\",\n",
    "    \"params\":{\"nlist\":32}\n",
    "}\n",
    "\n",
    "article_collection.create_index(\n",
    "    field_name=\"embeddings\",\n",
    "    index_params=index_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "data = glob.glob(\"data/*.txt\")\n",
    "all = []\n",
    "for file in data:\n",
    "    with open(file, 'r') as data_file:\n",
    "        lines = data_file.readlines()\n",
    "        text = ' '.join([str(elem) for elem in lines])\n",
    "        all.append(text)\n",
    "print(' '.join([str(elem) for elem in all]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and inserting vectors to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"\"\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "i = 0\n",
    "primary_keys = []\n",
    "titles = []\n",
    "embeddings = []\n",
    "file_names = []\n",
    "for file in data:\n",
    "    with open(file, 'r') as data_file:\n",
    "        lines = data_file.readlines()\n",
    "        title = lines[0]\n",
    "        text = ' '.join([str(elem) for elem in lines])\n",
    "        vector_embedding = get_embedding(text)\n",
    "        primary_keys.append(i)\n",
    "        titles.append(title)\n",
    "        file_names.append(data_file.name)\n",
    "        embeddings.append(vector_embedding)\n",
    "        i = i+1\n",
    "\n",
    "article_collection.insert([primary_keys, titles, file_names, embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question answering using Milvius search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_articles(question):\n",
    "    query_embeddings = get_embedding(question)\n",
    "    search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}, \"offset\": 0}\n",
    "\n",
    "    results = article_collection.search(\n",
    "        data=[query_embeddings],\n",
    "        anns_field=\"embeddings\",\n",
    "        param=search_params,\n",
    "        limit=1,\n",
    "        output_fields=['title', 'file_name'], # we retrieve also the URL field!\n",
    "        expr=None,\n",
    "        consistency_level=\"Strong\"\n",
    "    )\n",
    "\n",
    "    for result in results[0]:\n",
    "        return result.entity.get('file_name')\n",
    "\n",
    "def get_raw_text(file):\n",
    "    with open(file, 'r') as data_file:\n",
    "        lines = data_file.readlines()\n",
    "        return ' '.join([str(elem) for elem in lines])\n",
    "\n",
    "\n",
    "\n",
    "def get_final_answer(question, summaries):\n",
    "    prompt = f\"\"\"Use the below article to answer questions about benefits in our company, if you don't know the answer write \"Sorry I don't know the answer please contact HR:\n",
    "     Article:\n",
    "    \\\"\\\"\\\"\n",
    "    {summaries}\n",
    "    \\\"\\\"\\\"\n",
    "    Question: {question}?\n",
    "\"\"\"\n",
    "    response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, temperature=0, max_tokens=1000)\n",
    "    return response['choices'][0]['text']\n",
    "\n",
    "def answer(question):\n",
    "    article_collection.load()\n",
    "    article_candidates = find_articles(question)\n",
    "    context = get_raw_text(article_candidates)\n",
    "    final_answer = get_final_answer(question, context)\n",
    "    print(\"Odogovor u fajlu \" + article_candidates)\n",
    "    return final_answer\n",
    "answer(\"Give me best benefit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
